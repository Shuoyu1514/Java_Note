## 海量日志数据，提取出某日访问美团最多的ip，但是文件比较长上亿行，无法一次读入内存应该怎么做

- 注意到IP是32位的，最多有个2^32个IP
- 采用映射的方法，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map进行频率统计，然后再找出频率最大的几个）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。

## 一个机器只能处理1万行，小文件怎么分，访问有时候早上访问有时候晚上访问如何做规定不会把某些访问的ip 丢掉

- **处理热点**，对超过1万行的分片二次哈希，确保单机可处理每个子分片
- **忽略时间字段**：分片时仅依赖IP，避免因时间分散导致统计遗漏

## 常见的分布式 ID 解决方案

### 1. UUID（通用唯一标识符）

- 版本1：基于时间戳，包含时间戳和节点特定的信息（如 MAC 地址）。
- 版本4：随机生成，提供高度的唯一性。
- 优点：简单，广泛应用于多种编程语言中。
- 缺点：无序，较大（128位），不能轻易按生成时间排序。
- 适用场景：适用于排序要求不高的分布式系统，如对象存储或用户 ID。

### 2. Snowflake 算法（Twitter）

一个 64 位的 ID，包含以下部分：

- 41 位用于==时间戳==（从某个自定义的纪元开始的毫秒数）。
- 10 位用于==机器 ID==（数据中心或节点 ID）。
- 12 位用于==序列号==（确保同一毫秒内生成的多个 ID 是唯一的）。
- 优点：时间排序，具有良好的扩展性，支持高吞吐量（每个节点每毫秒最多生成 4096 个 ID）。
- 缺点：需要节点间时间同步。
- 适用场景：常用于分布式系统，如微服务或订单管理系统。

### 3. 数据库序列

数据库系统通常提供自增 ID 生成（例如 MySQL 的 AUTO_INCREMENT 或 PostgreSQL 的 SERIAL）。

- 优点：简单且可靠，适用于小型集中式系统。
- 缺点：无法很好地扩展到分布式系统，会引入单点故障。
- 适用场景：适用于无需高扩展性的简单应用。

### 4. KSUID（K-可排序的唯一标识符）

128 位 ID，嵌入时间戳和随机部分。

- 优点：ID 按生成时间可排序（字典序），比 UUID 更小。
- 缺点：稍微比 UUID 复杂，空间效率不如 Snowflake。
- 适用场景：适用于需要字典序排序和较长生命周期的场景，如日志聚合系统。

### 5. Redis / MongoDB 的序列生成器

像 Redis 或 MongoDB 这样的系统可以通过原子操作充当集中式的 ID 生成器。

- 优点：提供集中控制，并且具有高吞吐量。
- 缺点：存在单点故障，依赖 Redis/MongoDB 的可用性。
- 适用场景：适用于分布式系统，中央节点可以在没有高可用性要求的情况下生成 ID。

## **如果你发现某个接口响应很慢，该怎么排查？**

网络：对于单个请求来讲，网络因素影响其实很小，除非网络挂了导致请求超时才能意识到；而对于大批量请求，每个请求慢10ms，请求多了，时间也就长了，这种情况可以检查下你的应用部署机和数据库机地理位置是不是隔得很远，比如一个在华东一个在西南，地理距离也会对请求响应时间产生影响，请求量越大越明显； 

==应用层==：就是我们敲的controller、service那些代码，这一层出问题很好解决，因为代码毕竟都是我们敲的嘛，一<u>看日志</u>就大概知道什么原因，最多的就是出现死循环（当然一旦出现死循环也不只是响应慢那么简单了）；代码逻辑写的差点其实不会太影响性能，现在的cpu执行效率你尽管放心，再怎么优化也顶不了少一次io； 

==数据库事务==：检查下你的数据库是不是卡事务了，导致锁了很多表； 

==服务器自身==：服务器是不是卡了，cpu是不是炸了，内存是不是满了； 

==慢sql==：这一层出问题的几率很大，同一组查询结果，由于sql不同，耗时能相差几百上千倍，可以通过查看sql执行计划来排查问题，详见 mysql执行计划解析

> - JVM Full GC 频繁，GC 耗时严重
> - 内存泄漏：对象不断累积，无法 GC，导致堆内存膨胀 → GC频繁 → 响应变慢
> - 线程未及时回收，导致任务堆积
> - 日志阻塞：默认情况下，Log4j2 的日志写入是同步阻塞的——也就是调用线程会等到日志事件被真正输出才继续执行

## 第三方接口调用突增有什么处理办法？

| 类型       | 方法                           | 描述                             |
| ---------- | ------------------------------ | -------------------------------- |
| ⛔ 限流     | 限速、漏桶、令牌桶             | 限制单位时间内的调用次数         |
| 🕒 缓存     | 本地缓存、Redis 缓存           | 避免频繁请求相同数据             |
| 🧵 隔离     | 线程池/队列/熔断               | 防止接口异常拖垮主系统           |
| 📦 降级     | 返回默认值、本地数据、mock数据 | 第三方不稳定时返回兜底数据       |
| 🔁 重试机制 | 重试 + 指数退避                | 少量失败时自动补救，但要防止雪崩 |
| 📊 监控告警 | 请求量/失败率/响应时间等监控   | 提前发现问题，自动报警           |

## 对于大量的请求，如果此时缓存中还没有写入数据怎么办？

1. 缓存预热：在系统启动时，提前加载热点数据到缓存中，避免冷启动时的缓存穿透。
2. 互斥锁（Mutex Lock）：当缓存未命中时，只允许一个请求去数据库加载数据，其他请求等待，防止同时大量请求访问数据库。
3. 异步加载：缓存未命中时，立即返回一个默认值或错误，然后异步去加载数据到缓存，后续请求可以直接从缓存获取。
4. 缓存空对象（Cache Null）：如果数据库查询结果为空，也缓存这个空结果，避免频繁查询数据库。
5. 使用布隆过滤器（Bloom Filter）快速判断数据是否存在，避免查询不存在的数据。
6. 降级和限流：当数据库压力过大时，暂时降级服务，或者限制请求数量，保证系统不崩溃。

## 怎么防止短链重复

==对长链接做哈希<u>==取哈希值的一部分</u>（如前6-8位）作为短链

## 定时任务怎么保证不重复执行，不用redis怎么实现

- 利用==数据库唯一约束==

## 集群中怎么进行限流？如果机器能承接的流量不一致怎么设计负载均衡策略？会不会出现上游机器流量冲击下游的情况？

#### 1、

**本地限流（单机级）**：	Alibaba Sentinel

**分布式限流：**

- Redis + Lua 脚本：原子性强，适合 Token Bucket、漏桶
- Zookeeper：也能做计数，但不推荐用于高频限流
- Kafka、RabbitMQ 等消息中间件做“削峰填谷”

#### 2.

| **算法**                                  | **说明**                                             |
| ----------------------------------------- | ---------------------------------------------------- |
| **轮询（Round Robin）**                   | 简单平均，适用于机器性能一致                         |
| **加权轮询（Weighted Round Robin）**      | 给不同机器分配权重（如：A=1, B=3）                   |
| **最小连接数（Least Connection）**        | 当前连接数最少的优先                                 |
| **基于性能指标的负载均衡（如 CPU Load）** | 可结合 Prometheus/Agent 上报的实时指标做负载倾斜调整 |

**按权重 + 动态性能感知 + 实时调整**

#### 3.

**熔断 + 降级 + 缓存 + 异步削峰**

## *  如何设计一个秒杀场景？

秒杀场景的核心特点是**高并发、低库存、短时间爆发式访问** 。因此，设计时需要解决以下几个问题：

1.  **高并发处理** ：如何应对大量用户同时访问？
2.  **库存一致性** ：如何保证库存不会超卖或少卖？
3.  **用户体验** ：如何减少用户等待时间，避免页面崩溃？
4.  **防刷机制** ：如何防止恶意用户利用脚本抢购商品？

面对上面这些问题，可以针对每一层做一些设计：

![img](./%E5%9C%BA%E6%99%AF%E9%A2%98.assets/1739096327029-dc0c6de3-b7c5-415d-89f5-602c71a2a2de.png)

1、前端层：

+   **静态资源分离** ：将秒杀页面的静态资源（如HTML、CSS、JS）部署到CDN（内容分发网络），减轻服务器压力。
+   **请求拦截**：活动未开始时，前端按钮置灰；通过验证码、点击频率限制。

2、网关层：

+   **流量拦截** ：使用API网关对请求进行初步过滤，例如IP限流、黑名单拦截等。
+   **身份验证** ：通过Token或签名验证用户身份，防止未登录用户直接访问秒杀接口。

3、缓存层：

+   **Redis缓存库存** ：将商品库存信息存储在Redis中，利用其高性能特性处理库存扣减操作。
+   **预热数据** ：在秒杀活动开始前，将商品信息和库存数据加载到Redis中，减少数据库压力。

4、消息队列：

+   **削峰填谷** ：使用消息队列（如Kafka）将用户的秒杀请求异步化，避免直接冲击后端服务。
+   **订单处理** ：将成功的秒杀请求放入队列，由后台服务异步生成订单，提高系统吞吐量。

5、数据库层

+   **乐观锁**：在库存扣减时，使用乐观锁确保库存一致性。
+   **读写分离** ：通过主从复制实现数据库的读写分离，提升查询性能。

关键的核心业务逻辑实现，**库存防超卖方案采用：Redis原子操作 + 异步扣减数据库**。

![img](./%E5%9C%BA%E6%99%AF%E9%A2%98.assets/1739096621483-d55d61df-5bf6-4215-84a1-959414d88b27.png)

具体流程如下：

+   **秒杀请求达到**：用户发起秒杀请求，系统接收到请求后，首先进行一些基础校验（如用户身份验证、活动是否开始等）。如果校验通过，进入库存扣减逻辑。
+   **Redis库存扣减**：在Redis中检查商品库存是否充足。例如，使用`GET`命令获取当前库存数量。如果库存不足，直接返回失败，结束流程。如果库存充足，使用Redis的原子操作（如`DECR`或Lua脚本）扣减库存。
+   **异步更新数据库**：如果Redis库存扣减成功，生成一个秒杀成功的消息，并将其放入消息队列
+   **后台服务消费消息**：后台服务从消息队列中消费秒杀成功的消息，执行以下操作：
    +   1、为用户创建订单记录；
    +   2、使用乐观锁将数据库中的库存数量减少1；
    +   3、通过唯一标识（如用户ID+商品ID+时间戳）防止重复消费。
+   **最终一致性校验**：在Redis库存扣减和数据库库存更新之间，可能会存在短暂的不一致状态。为了保证最终一致性，可以采取以下措施：
    +   1、定期将Redis中的库存数据与数据库进行同步。
    +   2、如果发现Redis和数据库库存不一致，触发补偿逻辑（如回滚订单或调整库存）。

## *  设计题：订单到了半个小时，半个小时未支付就取消

有多种实现订单超时自动取消的技术方案，包括定时轮询、JDK的延迟队列、时间轮算法、Redis实现以及MQ消息队列中的延迟队列和死信队列。

+   定时轮询：基于SpringBoot的Scheduled实现，通过定时任务扫描数据库中的订单。优点是实现简单直接，但缺点是会给数据库带来持续压力，处理效率受任务执行间隔影响较大，且在高并发场景下可能引发并发问题和资源浪费。

+   JDK的延迟队列（DelayQueue）：基于优先级队列实现，减少数据库访问，提供高效的任务处理。优点是内部数据结构高效，线程安全。缺点是所有待处理订单需保留在内存中，可能导致内存消耗大，且无持久化机制，系统崩溃时可能丢失数据。

+   时间轮算法：通过时间轮结构实现定时任务调度，能高效处理大量定时任务，提供精确的超时控制。优点是实现简单，执行效率高，且有成熟实现库。缺点同样是内存占用和崩溃时数据丢失的问题。

+   Redis实现：

    +   有序集合（Sorted Set）：利用有序集合的特性，定时轮询查找已超时的任务。优点是查询效率高，适用于分布式环境，减少数据库压力。缺点是依赖定时任务执行频率，处理超时订单的实时性受限，且在处理事务一致性方面需要额外努力。

    +   Key过期监听：利用Redis键过期事件自动触发订单取消逻辑。优点是实时性好，资源消耗少，支持高并发。缺点是对Redis服务的依赖性强，极端情况下处理能力可能成为瓶颈，且键过期有一定的不确定性。

+   MQ消息队列：

    +   延迟队列（如RabbitMQ的rabbitmq\_delayed\_message\_exchange插件）：==实现消息在指定延迟后送达处理队列==。优点是处理高效，异步执行，易于扩展，模块化程度高。缺点是高度依赖消息队列服务，配置复杂度增加，可能涉及消息丢失或延迟风险，以及消息队列与数据库操作一致性问题。

    +   死信队列：==通过设置队列TTL将超时订单转为死信，由监听死信队列的消费者处理==。优点是能捕获并隔离异常消息，实现业务逻辑分离，资源保护良好，方便追踪和分析问题。缺点是相比延迟队列，处理超时不够精确，配置复杂，且同样存在消息处理完整性及一致性问题。

> **RabbitMQ + TTL + 死信队列**
>
> 1. 用户下单
> 2. 发送延迟消息（延迟 15 分钟）
> 3. MQ 到期 → 投递到死信队列
> 4. 消费死信 → 关闭订单 + 恢复库存

不同方案各有优劣，实际应用中应根据系统的具体需求、资源状况以及技术栈等因素综合评估，选择最适合的方案。在许多现代大型系统中，通常会选择==消息队列的延迟队列或死信队列方案==，以充分利用其异步处理、资源优化和扩展性方面的优势。

##  如果做一个大流量的网站，单Redis无法承压了如何解决？

+   读写分离：部署多个 Redis 从节点（Slave），主节点（Master）负责写操作，从节点负责读操作。主节点将数据同步到从节点，从节点可以处理大量的读请求，减轻主节点的压力。
+   构建集群：部署 Redis Cluster 集群，Redis Cluster 将数据自动划分为 16384 个槽（slots），每个槽都可以存储键值对。这些槽会被分配到多个 Redis 节点上，通过哈希函数将键映射到相应的槽，再由槽映射到具体的 Redis 节点。例如，使用 `CRC16(key) % 16384` 来确定键属于哪个槽，然后根据槽与节点的映射关系将键值对存储到相应节点。通过数据分片，将数据和请求分散到多个节点，避免单个节点的负载过高。不同节点负责不同的槽，各自处理一部分请求，实现负载均衡。

##  如何设计一个可重入的分布式锁，用什么结构设计？

可重入锁允许同一线程在持有锁的情况下多次获得锁而不会产生死锁。当线程请求锁时，如果它已经拥有了该锁，则可以直接获得锁，锁的计数器会增加。在释放锁时，计数器会减少，只有当计数器为零时，锁才会真正释放。

在分布式系统中，通常会使用诸如 Redis、Zookeeper 或 etcd 等组件来实现锁的管理。下面以 **Redis** 为例，简单描述如何设计一个可重入的分布式锁。

设计要素：

+   **锁的标识符（Lock ID）**：用于标识锁的唯一性。
+   **持有者标识（Owner ID）**：线程或进程的唯一标识符，通常是线程的 ID 或进程的 ID。
+   **计数器**：记录当前持有锁的次数。
+   **过期时间**：为了避免死锁，锁需要设定一个合理的超时时间。

我们可以在 Redis 中使用一个哈希表或简单的键值对来存储锁的状态。使用一个 key（如 `lock:<resource>`）来表示锁，包含以下字段：

+   `owner`: 当前持有锁的线程/进程标识符
+   `count`: 当前计数器，表示获得锁的次数
+   `expires_at`: 锁的到期时间，用于防止死锁

示例数据结构

```plain
{
  "key": "lock:resource_1",
  "value": {
    "owner": "thread_id_or_process_id",
    "count": 3,
    "expires_at": "2023-10-01T12:00:00Z"
  }
}
```

以下是围绕这个锁结构的基本操作：

1.  获取锁 (Lock Acquisition)：尝试设置 lock: 的值，如果这个 key 不存在（即没有锁），那么可以创建该 key，并设置 owner 为当前线程/进程的唯一ID，count 设为 1，expires\_at 设为当前时间加上锁的过期时间。 如果该 key 已存在且 owner 是当前线程/进程的 ID，则增加 count 并更新 expires\_at。
2.  释放锁 (Lock Release)：检查当前的 owner 是否是当前线程/进程的 ID。如果是，减少 count。如果 count 减少到 0，则删除该 key。 如果在持有锁的情况下，锁已过期，系统会根据 expires\_at 检查锁是否可释放，避免死锁。
3.  锁续期 (Lock Renewal)：如果当前线程在执行过程中需要继续持有锁，可以在逻辑处理中重新设置 expires\_at.
4.  超时与故障恢复：可以设置锁的自动超时时间，例如，设定一个最大持锁时间，超时后锁自动释放。这可以在一定程度上防止死锁的情况。

整体流程示例：

+   **获取锁**：

    +   线程A调用获取锁的 API。如果成功，返回锁的状态。

    +   如果线程B也尝试获取同一把锁，则会返回锁已被占用。

+   **释放锁**：

    +   线程A在完成任务时调用释放锁的 API，递减 `count` 字段。

    +   如果 `count` 达到 0，删除锁并释放资源。

+   **续约锁**：

    +   线程A在处理过程中可以根据需要续约锁，更新 `expires_at`。

##  你有看过一些负载均衡的一些方案吗

+   **硬件负载均衡**：使用专用的硬件设备（如负载均衡器）来分配流量，比如F5设备，优点是性能强大，支持高并发。缺点是成本太高，通常一个专业级的硬件设备，都需要百万级别的价格。
+   **软件负载均衡**：使用软件应用程序来实现负载均衡，可以运行在普通服务器上，比如 **Nginx** 支持反向代理和负载均衡，优点灵活性高，成本低，易于修改和扩展，缺点是性能不如硬件负载均衡，但是软件负载均衡的性能也足够应对大多数场景的并发量了。
+   **DNS 负载均衡**：通过 DNS 服务器将流量分配到多个服务器上，不同的客户端请求可能获得不同的 IP 地址。优点是简单易用，不需要额外的硬件或软件。缺点是无法智能感知服务器的实时状态，缓存问题可能导致不均匀负载。
+   **内容分发网络 (CDN)**：CDN 是一种分布式的网络结构，可以将内容分发到离用户最近的节点上。优点减少延迟，提高用户体验。缺点主要适用于静态内容，动态请求仍需其他形式的负载均衡。

* * *

## traceid底层原理怎么实现的？多个线程怎么做到都能记录到？

#### 1.

TraceId 是一条请求链唯一标识符，用来串联一次请求在多个服务中的调用路径。

一般在入口处生成（如 Nginx、Gateway、Controller）

通常使用：

- UUID
- ==雪花算法==（如 Zipkin）
- 时间戳 + 机器号 + 线程Id

#### 2.

**✅ 1. 手动传递 TraceId（业务代码中透传）**

**✅ 2. 使用线程池包装工具（更优雅）** **TransmittableThreadLocal (TTL)**

#### 3.

**跨服务如何传递 TraceId？**

| 同线程内 | ThreadLocal                                |
| -------- | ------------------------------------------ |
| 子线程   | ==InheritableThreadLocal==（不适用线程池） |
| 线程池   | 手动传递 / ==TTL 方案==（线程池包装工具）  |
| 异步任务 | MDC 透传或包装 Runnable                    |
| 跨服务   | 放入 ==Header==，再取出写入 ThreadLocal    |

## 如果想在一个jvm进程中同时调用两个版本的jar 包应该怎么做

- 需要用==两个不同的类加载器==（通常是自定义的 URLClassLoader），并==打破双亲委派模型==实现类隔离。

- 这样同一个类名（如 com.xxx.A）被不同 ClassLoader 加载后，在 JVM 中视为不同类，互不干扰。可以用于插件化、SDK 隔离、版本兼容场景。

## 线上 OOM（OutOfMemory）问题排查指南

首先确认是哪种 OOM 错误，常见的几种类型：

1. **Java heap space** - 堆内存溢出
2. **Metaspace** - 元空间溢出（Java 8+）或 PermGen 溢出（Java 7-）
3. **Unable to create new native thread** - 线程数过多
4. **Direct buffer memory** - 直接内存溢出（NIO）
5. **GC overhead limit exceeded** - GC效率低下

## 100个entry放入map中应该多大参数

**256个**

128 x 0.75 = 96

## 消息队列相比spring task的好处

Spring Task 更轻，更快上手；消息队列更强，更稳定，更适合分布式场景。

### 什么时候用 Spring Task（适合轻量级场景）

- ==简单==的定时任务（如每 5 分钟执行一次统计）
- 本地异步执行，不需要==消息持久化==
- ==非核心流程==失败无所谓
- 开发快、上线快、依赖少

## 登录的时候，集成多个登录系统做SSO怎么做？

SSO（Single Sign-On）即单点登录，用户在一次登录后，可以访问多个系统，无需重复登录。

> - 用户访问业务系统 A
> - A 检查无 token，重定向到 SSO Server 登录页
> - 用户选择钉钉扫码登录 → 扫码成功 → SSO Server 登录成功
> - SSO Server 生成 Token（如 JWT）并带回系统 A
> - 系统 A 校验 token，获取用户信息，完成登录

SSO Server 提供统一入口，比如 /login，再内部区分各种登录方式：不同方式内部实现不同认证逻辑，但最终统一为一个用户上下文。

## a = a+b和a+=b在编译上有什么区别？

- a = a + b 会触发 **自动类型提升**，如果类型不兼容会编译报错；
- a += b 是 Java 提供的语法糖，编译器会自动插入 **隐式类型转换**，所以不会报错；
- 实际开发中，建议使用 += 更简洁安全，尤其在处理 short、byte、char 类型时。

## 报表系统

1.报表主表（report）

| **字段**                     | **类型** | **说明**      |
| ---------------------------- | -------- | ------------- |
| id                           | bigint   | 报表ID        |
| name                         | varchar  | 报表名称      |
| current_published_version_id | bigint   | 当前发布版本  |
| create_time / update_time    | datetime | 创建/更新时间 |

2. 报表版本表 report_version

| **字段**    | **类型**                        | **说明**                         |
| ----------- | ------------------------------- | -------------------------------- |
| id          | bigint                          | 报表版本ID                       |
| report_id   | bigint                          | 所属报表ID                       |
| status      | enum(DRAFT, PUBLISHED, HISTORY) | 当前版本状态                     |
| content     | json/text                       | 报表配置内容（图表、指标、维度） |
| version_num | int                             | 版本号或时间戳，用于排序         |
| create_time | datetime                        | 创建时间                         |

## 场景题（供货＋分拣+派麻）设计模式

| 模块 | 设计模式              | 说明                                           |
| ---- | --------------------- | ---------------------------------------------- |
| 供货 | 工厂模式              | 不同类型供货商创建不同的商品入库策略           |
| 分拣 | 策略模式 + 责任链模式 | 分拣流程有多个环节（验货、拣货、打包），可解耦 |
| 派麻 | 观察者模式 + 状态模式 | 监听订单状态、调度配送方式（自提、快递）       |

- 工厂模式，可能用于供货环节，根据不同的供应商创建不同的供货渠道
- 策略模式：按不同规则分拣（重量优先、紧急订单优先）
- 观察者模式：当货物进入派送环节时，通知多个子系统（库存系统、用户通知系统）
- 责任链：分拣失败时，逐级尝试恢复（重试分拣 → 转人工 → 退回供应商）
  - 允许对象沿着处理链传递请求，直到有一个对象处理它。这种模式通常用于处理多个对象都有可能处理请求的情况，比如异常处理、事件处理
- 状态模式：管理订单状态转换（供货中 → 已分拣 → 派送中 → 已完成）
## 10亿整数中找最大的100个数
==分治 加最小堆==
先把`10`亿个数分成`100`份，每份`1000w`个数，然后在`1000w`个数中分别找出最大的`100`个数，最后在`100*100`个数中找出最大的`100`个


一般提到海量数据排序都默认计算机内存不足以同时放下所有数据。因此海量数据排序需要使用到分治的思想，最常见的就是==多路归并排序和位图法。==
## 对40亿qq号去重
针对 4,000,000,000 个可能的 QQ 号，需要的内存约为 500  MB

-  初始化位数组：分配一个足够大的位数组（或称为 bitmap），其大小至少能覆盖 QQ 号的整个范围。所有位初始为 0。

- 遍历输入数据
  - 对于输入的每个 QQ 号 qq：

  - 检查 bitmap[qq] 是否为 0：

  - 如果为 0，表示该 QQ 号第一次出现，将其对应位设为 1，同时记录或输出该 QQ 号。

  - 如果已经为 1，则说明该 QQ 号已经出现过，直接跳过，达到去重效果。

- 输出或存储结果：遍历结束后，所有被置为 1 的位置就代表所有唯一的 QQ 号。

## 如何设计一个秒杀系统

### 如何处理热点数据？

热点数据一定要放在缓存中，并且最好可以写入到 jvm 内存一份（多级缓存），并设置个过期时间。需要注意写入到 jvm 的热点数据不宜过多，避免内存占用过大，一定要设置到淘汰策
略。
为什么还要放在 jvm 内存一份？ 因为放在 jvm 内存中的数据访问速度是最快的，不存在什么网络开销。

### 流量削峰

把这些请求放到消息队列中去。然后，咱后端服务再慢慢根据自己的能力去消费这些消息

### 回答问题/验证码

避免用户请求过于集中，另一方面可以有效解决用户使用脚本作弊。

### 集群化

Nginx 集群、Kafka 集群、Redis 集群。

Redis 来举例说明。

- 直接通过 Redis replication（异步复制） 搞个一主(master)多从(slave)来提高可用性和读吞吐量，并使用通过 Sentinel（哨兵） 来解决主节点宕机问题

### 限流

Sentinel

### 排队

你可以把排队看作是限流的一个变种。限流是直接拒绝了用户的请求，而排队则是让用户等待一定的时间

### 降级

服务降级指的是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行

举个例子：当请求量达到一个阈值的时候，我们对系统中一些非核心的功能直接关闭或者让它们功能降低

### 熔断

降级的目的在于应对系统自身的故障，而熔断的目的在于应对当前系统依赖的外部系统或者第三方系统的故障。

熔断可以防止因为秒杀交易影响到其他正常服务的提供

举个例子：

一个订单服务调用库存服务，如果：

- 调用库存接口失败率连续超过 50%，
- 或者响应时间超过阈值，

就会**启动熔断**：**短时间内直接失败，不再请求库存服务**

### 一致性

下单即减库存 

### 接口幂等

1. 同步锁；
2. 分布式锁；
3. 业务字段的唯一索性约束，防止重复数据产生。

## 如何自己实现一个RPC框架

RPC 框架不仅要提供服务发现功能，还要提供负载均衡、容错等功能

## 排行榜

1. MySQL 的 ORDER BY 关键字

2. Redis 的 sorted set

# 抽奖系统

其实对于商品秒杀、抽奖活动、抢红包类的系统而言，架构设计的思路很多都是类似的，核心思路都是对于这种瞬时超高流量的系统，尽可能==在负载均衡层就把99%的无效流量拦截掉==

然后在1%的流量进入核心业务服务后，此时每秒并发还是可能会上万，那么可以基于Redis实现核心业务逻辑 ，抗住上万并发。

最后对于类似==秒杀商品发货、抽奖商品发货、红包资金转账之类的非常耗时的操作，完全可以基于MQ来限流削峰==，后台有一个服务慢慢执行即可。

![image-20250410142619647](./%E5%9C%BA%E6%99%AF%E9%A2%98.assets/image-20250410142619647.png)

> 用户请求抢红包
>     ↓
> Nginx/API网关
>     ↓
> Redis (Lua 脚本：抢红包逻辑)
>     ↓            ↓
>  成功        失败（没抢到）
>     ↓
> 消息队列（异步入库）
>     ↓
> MySQL/Mongo 持久化记录

# 短链系统

用**“302”**作为状态码

### 唯一短链生成：

使用非加密型哈希算法比如 MurmurHash

> 效率更高

### 如何判断是否发生了哈希冲突呢？

添加唯一索引

建议利用布隆过滤器解决这个问题

### 如何解决哈希冲突呢？

在长链后拼接一个随机字符串。如果拼接了随机字 符串还是发生哈希冲突那就再拼接一个随机字符串

# 如何设计一个站内消息系统



# 如何设计微博Feed流/信息流系统

### 推模式

当一个用户发送一个动态（比如微博、视频）之后，主动将这个动态推送给其他相关用户（比如粉 丝）。

将这个动态插入到每位粉丝对应的 feed 表中，这个==存储成本是比较高的==

### 拉模式

拉模式下我们是自己主动去拉取动态（拉取你关注的人的动态），然后将这些动态根据 相关指标（比如时间、热度）进行实时聚合

### 推垃结合模式

- 区分出系统哪些用户属于微博大 V
- 判断哪些用户属于不活跃用户
- 当微博大 V 发送微博的时候，我们仅仅将这条微博写入到活跃用户，不 活跃的用户自己去拉取

![image-20250412172832661](./%E5%9C%BA%E6%99%AF%E9%A2%98.assets/image-20250412172832661.png)

### 存储

==MySQL + Redis== 。MySQL 永久保存数据， Redis 作为缓存提高热点数 据的访问速度。

如果缓存的数据量太大怎么办? 我们可以考虑使用==Redis Cluster==，也就是 Redis 集群。Redis Cluster 可以帮助我们解决 Redis 大数据量缓存的问题
