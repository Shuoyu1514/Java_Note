

### 反问：

技术栈

候选人资质

面试之后学习什么地方

# 实习

### 分片上传与断点续传

<img src="./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250410202055757.png" alt="image-20250410202055757" style="zoom:50%;" />

> 唯一标识都是通过对==文件的名称、最后修改时间==等信息取MD5值得到

# 项目1

## 数据库设计

<img src="./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250331170841843.png" alt="image-20250331170841843" style="zoom:50%;" />

## 权限控制

### 1.短信登录

#### 发送验证码

1.校验手机号

2.如果不符合，返回错误信息

3.符合，生成验证码

4.保存验证码到 session

5.发送验证码

```
key：LOGIN_CODE_KEY + phone
value：code
TTL
```

#### 用户登录

1.校验手机号

3.从redis获取验证码并校验

4.一致，根据手机号查询用户 select * from tb_user where phone = ?

5.判断用户是否存在

6.不存在，创建新用户并保存

7.保存用户信息到 redis中

8.随机生成token，作为登录令牌

> 客户端只保存令牌，不能篡改
>
> ==头部：加密算法==
>
> ==载荷：实际要传输的信息==
>
> ==签名：用于校验头部和载荷是否被篡改；==



### Session共享

问题：每个tomcat中都有一份属于自己的session,假设用户第一次访问第一台tomcat，并且把自己的信息存放到第一台服务器的session中，但是第二次这个用户访问到了第二台tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的session，所以此时 整个登录拦截功能就会出现问题

保存登录的用户信息，可以==使用String结构==，以JSON字符串来保存

![image-20250410195807182](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250410195807182.png)

> 服务端把session存放在redis中；
>
> 客户端：Cookie（最常见）；LocalStorage / SessionStorage（如果是SPA）；请求 Header
>
> 无状态认证（JWT），token 本身带有用户信息，不需要服务端存储。



### 双重拦截器

- 前置拦截器——对**所有请求**都执行 Token 解析与刷新，并把解析好的用户信息放到 ThreadLocal 里
- 后置拦截器——只作用于**需要鉴权**的请求，判断用户数据是否已存在于 **ThreadLocal**，若不存在则拒绝访问。

### 查询附近商铺功能，如果有十万多家商品，怎么做？

Redis 的 GEO 数据结构

使member只存店铺的id。将来搜索附近店铺的时候，根据经纬度坐标进行筛选，筛选以后再根据id来查询数据库即可。

>  **“冷数据放 MySQL，热数据放 Redis，全文+复杂搜索走 ES”**

### 2.探店点评、点赞

post

set

### 3.签到功能

```java
sign:user:{userId}:{yyyyMM}
```

==把年和月作为bitMap的key==，然后保存到一个bitMap中，每次签到就到对应的位上把数字从0变成1，只要对应是1，就表明说明这一天已经签到了，反之则没有签到

![image-20250410202906187](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250410202906187.png)



位是从右往左累加的

### 4.好友关注

set

### 主动更新策略

- 在对数据库（DB）中的数据进行更新（增、删、改）后，主动去更新（或删除）Redis 中的对应缓存数据，而不是等到缓存自然过期。

### 随机 TTL 机制

- 设置缓存时，给每条缓存数据一个随机过期时间，通常是在一个基础过期时间上再加上一个随机浮动值。

### 逻辑过期

- 核心思想：在 Redis 中保存的并不是一个真正“物理过期”的键，而是一个“带有过期时间字段（逻辑过期时间）”的数据对象。
- 当过期时间到时，Redis 中并不会自动删除这个 Key，而是由业务逻辑判断该缓存是否过期。
  - 如果逻辑上过期：可能会有一个单独的线程（或异步任务）去后台重建缓存。在此期间，仍旧可以把旧缓存返回给用户，避免瞬时大量请求直击数据库。
  - 如果没过期：直接返回缓存中的数据。

### 布隆过滤器

- 初始化
  - 启动时，把所有可能存在的“有效 Key”集合（如商品 ID、用户 ID、帖子 ID 等）加载到布隆过滤器中。
  - 注意定期维护或增量更新布隆过滤器，以免数据不完整而拦截了合法请求。
- 请求到来时，首先检查布隆过滤器：
  - 如果判断“不存在”，则直接返回“该资源不存在”或“404”。无需再访问 Redis 和数据库。
  - 如果判断“可能存在”，再去访问缓存。如果缓存也没有，就访问数据库，并根据数据库结果做相应处理（缓存“空对象”或插入真实数据）。
- 数据更新
  - 数据库中有新的有效 ID 加入时，也需要把这个 ID 放入布隆过滤器，以免被误判不存在。
  - 如果有 ID 被删除或失效，理论上布隆过滤器无法准确移除（除非使用可删除布隆过滤器或重建），需要设计合理的过期机制或定期全量重建。

> 布隆过滤器并不能完全避免所有的无效 Key 请求，因为它存在**误判**（false positive）——即某些不存在的 Key 可能被判断为“可能存在”。但相对于“正常的”哈希表，布隆过滤器节省大量空间且能够有效减少大部分不存在Key的查询。

### 秒杀下单

1、查询优惠卷剩余数量

2、判断秒杀库存是否足够

3、查询订单

4、校验是否是一人一单

5、扣减库存

6、创建订单

### 分布式锁

分布式锁：满足分布式系统或集群模式下多进程可见并且互斥的锁。

### 集群模式如何获取锁？

==RedLock== 旨在解决「Redis 节点宕机导致锁不可靠」的问题。

使用 N 个完全独立的 Redis 实例（通常是 5 个），在多个实例上独立地尝试加锁，只要成功获得超过半数节点的锁（如 3/5），即认为锁获取成功

> 1. 生成一个唯一的锁 ID（如 UUID + 线程 ID）
> 2. 并发地向 5 个 Redis 节点尝试加锁（使用 SET key value NX PX 3000）
> 3. 在规定时间内（如几百毫秒）成功拿到超过半数（如 ≥3）个锁
> 4. 计算加锁耗时，确认是否在锁有效时间内（避免时间漂移问题）
> 5. 如果成功，加锁成功；否则释放所有锁并重试

#### 存在问题？

时钟跳跃问题：如果某节点发生时钟回拨，可能导致锁提前释放

 持久化延迟问题：Redis节点未持久化即崩溃，节点快速重启后，客户端B也能获得相同锁

### Lua脚本

- 校验用户购买次数
- 校验库存
- 扣减库存 & 增加用户购买次数
- 成功

### 为什么使用lua脚本，不能直接操作数据库？

Lua 脚本在 Redis 中的执行是**原子性的**。也就是说，整个脚本会一次性执行完，**中途不会被其他命令插队**

> 如果不使用，则会发生并发问题（库存超卖、重复下单）

### 布隆过滤器

使用redis的bitmap来实现

| 参数 | 含义                                          |
| ---- | --------------------------------------------- |
| n    | ==预估要存储的元素数量（比如 100 万个用户）== |
| p    | ==可接受的误判率（比如 1% 或 0.01）==         |
| m    | 位图长度（bit 数）← 这就是你问的「设置多大」  |
| k    | 哈希函数个数                                  |

通常会根据 n 和 p 来反推出 m 和 k

![image-20250403090726395](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250403090726395.png)

### 秒杀项目中，一般哪里会使用事务？

库存扣减 + 订单生成（核心）

- ==用户抢购成功 → 扣 Redis 库存 → 推送消息到 MQ（Kafka/RabbitMQ）→ 消费者异步落库（写订单、扣库存、记录日志）==
- 用户请求成功后，我们在后台要执行：这些步骤必须原子完成，一旦中间某一步失败，就会数据不一致
  - 写订单
  - 扣库存（MySQL 库存表）
  - 插入抢购记录

### Leaf 雪花算法

![image-20250413111916482](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250413111916482.png)

美团Leaf雪花算法解决时钟回拨的方案：

- 回拨检测：在每次生成ID时，会将当前的系统时间与上一次生成ID使用的时间进行比较

#### 流程

1. 启动Leaf-snowflake服务，连接Zookeeper，在leaf_forever父节点下检查自己是否已经注册过（是否有该顺序子节点）。
2. 如果有注册过直接取回自己的workerID（zk顺序节点生成的int类型ID号），启动服务。
3. 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的workerID号，启动服务。

> 除了每次会去ZK拿数据以外，也会在本机文件系统上缓存一个workerID文件。当ZooKeeper出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。

#### 时钟回拨

服务启动时首先检查自己是否写过ZooKeeper leaf_forever节点：

1. 若写过，则==用自身系统时间与leaf_forever/${self}节点记录时间做比较==，若小于leaf_forever/${self}时间则认为机器时间发生了大步长回拨，服务启动失败并报警。
2. 若未写过，证明是新服务节点，直接创建持久节点leaf_forever/${self}并写入自身系统时间，接下来综合对比其余Leaf节点的系统时间来判断自身系统时间是否准确，具体做法是取leaf_temporary下的所有临时节点(所有运行中的Leaf-snowflake节点)的服务IP：Port，然后==通过RPC请求得到所有节点的系统时间，计算sum(time)/nodeSize==。
3. 若abs( 系统时间-sum(time)/nodeSize ) < 阈值，认为当前系统时间准确，正常启动服务，同时写临时节点leaf_temporary/${self} 维持租约。
4. 否则认为本机系统时间发生大步长偏移，启动失败并报警。
5. 每隔一段时间(3s)上报自身系统时间写入leaf_forever/${self}。

# 项目2

### 分布式理论CAP

CAP 定理中，三个字母分别代表这些含义：

- C，Consistency 单词的缩写，代表==一致性==，指分布式系统中各个节点的数据保持强一致，也就是每个时刻都必须一样，不一样整个系统就不能对外提供服务

- A，Availability 单词的缩写，代表==可用性==，指整个分布式系统保持对外可用，即使从每个节点获取的数据可能都不一样，只要能获取到就行

- P，Partition tolerance 单词的缩写，代表分区==容错性==。


所谓的 CAP 定理，就是指在一个分布式系统中，CAP 这三个指标，<u>最多同时只能满足其中的两个，不可能三个都同时满足</u>

### BASE 理论

- 基本可用（Basically Available）：系统出现故障还是能够对外提供服务，不至于直接无法用了

- 软状态（Soft State）：允许各个节点的数据不一致

- 最终一致性，（Eventually Consistent）：虽然允许各个节点的数据不一致，但是在一定时间之后，各个节点的数据最终需要一致的


### OpenFeign和feign的区别

> **Feign 是原生的 HTTP 客户端框架，OpenFeign 是 Spring Cloud 对它的增强版，是当前主流使用方式。**

### 为什么使用微服务

- **单一职责**：一个微服务负责一部分业务功能，并且==其核心数据不依赖于其它模块==。
- **团队自治**：==每个微服务都有自己独立的开发==、测试、发布、运维人员，团队人员规模不超过10人
- **服务自治**：==每个微服务都独立打包部署，访问自己独立的数据库==。并且要做好服务隔离，避免对其它服务产生影响

### **OpenFeign 的底层**

基于 **动态代理** 和 **HTTP 请求模板化** 实现的声明式 HTTP 客户端框架

#### 实现流程：

1. **动态代理生成客户端**：当定义一个 OpenFeign 客户端接口时，OpenFeign 会通过动态代理生成接口的实现类。生成的代理对象负责==将接口方法转换为 HTTP 请求==
2. **请求模板解析（Contract）**：使用 **`Contract`** 接口解析接口方法和注解，生成请求模板（定义 URL、HTTP 方法、参数位置等）
3. **编码器与解码器**：将 Java 对象转换为 HTTP 请求体，将 HTTP 响应体转换为 Java 对象

> - 默认支持 HTTP/1.1， OkHttp支持 HTTP/2
> - OpenFeign 默认集成 Spring 的 `HttpMessageConverter`，Jackson

### 分布式服务的接口幂等性如何设计？

候选人：
我们通过Token和Redis来实现接口幂等性。用户操作时，系统生成一个Token并存储在Redis中，当用户提交操作时，系统会验证Token的存在性，并在验证通过后删除Token，确保每个Token只被处理一次。

### 如果有大数据量的任务同时都需要执行，怎么解决？

候选人：
我们可以通过部署多个实例并使用分片广播路由策略来分散任务负载。在任务执行代码中，根据分片信息和总数对任务进行分配。

###  **Seata**

```yaml
1. 构建订单基本信息
2. 查询商品 + 计算总价
3. 补充订单属性 + 保存订单
4. 保存订单详情
5. 清除购物车中的已购买商品
6. 扣减库存
7. 发送延迟消息检测支付状态

创建订单+清除购物车+扣减库存
```

Seata 的目标是始终是==对业务无入侵的方案。==

在Seata的事务管理中有三个重要的角色：

- TC是==服务器==端组件，负责全局事务的协调
- TM和RM是==客户端==组件，TM负责定义事务边界，RM管理分支事务的资源。
- **Transaction Coordinator (TC)**： 事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。
- **Transaction Manager (TM)**： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。
- **Resource Manager (RM)**： 控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。

1. TM 向 TC <u>申请开启一个全局事务</u>，TC 创建全局事务后返回全局唯一的 ==XID==，XID 会在全局事务的上下文中传播；
2. RM 向 TC 注册分支事务，该分支事务归属于拥有相同 XID 的全局事务；
3. TM 向 TC <u>发起全局提交或回滚</u>；
4. TC 调度 XID 下的分支事务完成提交或者回滚。

> TM、RM都只与TC通信

![image-20250325133912737](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250325133912737.png)

####  AT模式二阶段提交

阶段一`RM`的工作：

- 注册分支事务
- 记录undo-log（数据快照）
- ==执行业务sql并提交==
- 报告事务状态

阶段二提交时`RM`的工作：

- 删除undo-log即可

阶段二回滚时`RM`的工作：

- 根据undo-log恢复数据到更新前

####  XT模式二阶段提交

一阶段：

- 事务协调者通知每个事务参与者执行本地事务
- 本地事务执行完成后报告事务执行状态给事务协调者，此时==事务不提交==，继续持有数据库锁

二阶段：

- 事务协调者基于一阶段的报告来判断下一步操作
- 如果一阶段都成功，则通知所有事务参与者，提交事务
- 如果一阶段任意一个参与者失败，则通知所有事务参与者回滚事务

#### 对比

XA：优点是==对业务代码无入侵==，但是它的缺点也是很明显：必须要求数据库==对 XA 协议的支持==，且由于 XA 协议自身的特点，它会==造成事务资源长时间得不到释放，锁定周期长==

#### 通信

Seata 在技术层面是通过 ==Netty== 作为 RPC 框架来完成 TM、RM 与 TC 之间的网络通讯

#### undolog

在 Seata AT 模式下，每次分支事务执行数据库操作时，会<u>在业务所使用的同一个数据库</u>中记录相应的 Undo Log（默认会在同一个库内自动创建名为 undo_log 的表）

#### Netty

基于 **NIO**（Non-blocking I/O）并采用 **Reactor 模型**的网络通信框架，主要针对高性能、高可扩展性场景做了大量优化

Netty 默认使用多线程 Reactor（Boss + Worker）：

- Boss 线程组：接收客户端连接（ServerSocketChannel），并把新的 Channel 注册到 Worker 线程组；
- Worker 线程组：处理实际的读写事件。

> ByteBuf、零拷贝，以提高吞吐和减少 GC

### Sentinel

Sentinel 的 ==WebSocket== 通信是基于 ==Netty== 实现的，性能更高

### 限流

基于QPS/TPS

Sentinel 通过==滑动窗口算法==进行实时统计，请求进入前先判断是否超过限流阈值

- 执行 fallback 方法

#### 熔断降级

Sentinel 的熔断（降级）是 **基于统计指标自动触发的“断路器”机制**，分为三种策略：

| 策略       | 描述                                    | 场景         |
| ---------- | --------------------------------------- | ------------ |
| 慢调用比例 | RT（响应时间）超过阈值 + 慢调用比率过高 | 接口响应很慢 |
| 异常比例   | 一段时间异常比例超过设定值              | 服务抖动     |
| 异常数     | 每秒异常数过多                          | 接口雪崩风险 |

- 通过并发线程数进行限制

- 通过响应时间对资源进行降级

- 利用**责任链**中的各个 Slot 模块对请求进行预处理、实时统计和规则校验，
- 通过高效的**滑动窗口**数据结构（LeapArray + WindowWrap + MetricBucket）实时采集流量数据，
- 根据预配置的限流规则（QPS、并发数、预热、排队等）决定是否放行请求或触发降级措施。

> ==降级是 熔断之后的补救机制==

### **Nacos**

#### 功能

> - 动态配置服务：数据库连接字符串、线程池大小等运行时参数的调整
>
> - 服务健康监测

特别注意：

- 仅适用于：
  - 限流阈值、规则
  - 业务规则参数（最大可下单数、系统阈值、超时时间）

```yaml
- dataId: shared-jdbc.yaml # 共享mybatis配置
- dataId: shared-log.yaml # 共享日志配置
- dataId: shared-swagger.yaml # 共享日志配置
- dataId: shared-seata.yaml # 共享seata配置
```

**解决思路：**

- **滚动升级：**对于数据库连接、MQ 连接、RPC 客户端等，需要**“重建或重初始化”底层对象**才能真正使用新参数，一般通过CI/CD 流水线中修改环境变量（或 Nacos 中的配置），然后部署一批新实例先起来，再下线旧实例。

#### 连接方式

从Nacos 2.0版本开始，UDP推送被废弃，转而采用==基于gRPC的双向流通信==

> gRPC 是基于Netty的，基于 ==HTTP/2==，支持多路复用（Multiplexing）、头部压缩、流式传输等特性

- 建立连接： 客户端与Nacos Server之间建立长期的gRPC双向流连接，这是一种==全双工通信方式==，即双方都可以同时发送数据而无需等待对方响应。
- 实时推送： 当配置发生变更时，Nacos Server通过已建立的gRPC连接即时推送配置更新至客户端，确保数据的实时性和可靠性。
- 资源高效： 相比UDP，gRPC提供了连接管理和流量控制，减少了因网络不稳定导致的消息丢失问题，同时也降低了服务器资源的消耗。
- 安全增强： gRPC支持==TLS加密==，进一步提升了数据传输的安全性。

心跳实现：

- 连接本身的心跳机制，断开就直接剔除服务实例
- Nacos 主动检查机制，服务端会对 20s 没有发送数据的连接进行检查，出现异常时也会主动断开连接，剔除服务实例

#### 配置中心

- 对网关设置==动态路由==

### 镜像队列与死信队列

#### 镜像

- 队列的 master 节点负责处理请求（读写）；
- slave 节点会同步消息副本；
- 如果 master 节点挂了，slave 会自动“晋升”为新的 master，继续服务！

#### 死信

| **场景**                                                     | **描述**                              |
| ------------------------------------------------------------ | ------------------------------------- |
| 1️⃣ 消息被拒绝（basicReject 或 basicNack），且 requeue = false | 消费失败，且不重新入队                |
| 2️⃣ 消息 TTL 过期                                              | 消息过了设置的存活时间                |
| 3️⃣ 队列达到最大长度                                           | 队列设置了 max-length，溢出消息被丢弃 |

某个正常队列绑定了一个死信交换机 DLX，如果消息“死掉”了，就被路由到这个交换机 → 然后投递到死信队列。

> 订单过期：
>
> 下单成功后，我们向一个设置了 TTL 和死信交换机属性的延迟队列发送一条消息。若用户在 30 分钟内未付款，消息就会自动过期并被 RabbitMQ 投递到死信队列中，我们的消费者监听该队列后，执行订单状态变更和资源回收等操作。

### 同一用户通信

在微服务发起调用时把用户信息存入请求头。

### 核心功能

![image-20250411091405750](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250411091405750.png)

![image-20250411091412945](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250411091412945.png)

![image-20250411091422460](./13.%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87.assets/image-20250411091422460.png)

### DDD架构

DDD（领域驱动设计）是一种以业务为核心、以领域模型为中心的软件设计思想，通过将复杂业务建模为“==领域 + 聚合 + 实体 + 值对象==”等概念，使业务逻辑具备高内聚、低耦合、可演进、可理解的特性

```java
用户界面层（Controller）
        ↓
应用服务层（Application Service） ← 事务控制、调用聚合根
        ↓
领域模型层（Domain Model） ← 核心业务逻辑
        ↓
基础设施层（Infrastructure） ← 数据库、MQ、三方服务、持久化
```

# 未来三年规划

第一年：夯实基础 + 深度参与项目

- 第一年会把书面知识转化为实际开发中的知识，通过不断的学习提升自己的业务水平

第二年：系统设计能力 + 技术深度提升

- 之后不断学习系统设计、架构设计基本能力，如高并发处理、数据库设计、缓存设计、服务拆分等；
- 阅读开源项目（如 Spring 源码、RocketMQ、Netty），提升底层理解；

第三年：架构思维 + 技术领导力

- 深入理解分布式系统、高可用架构、微服务治理等架构级能力；
- 主导一个完整子系统或关键业务模块的技术方案与落地；

## 大模型幻觉

大模型生成了看起来“有道理”，但实际上是错误、不真实甚至是胡编乱造的信息。

> 明确要求引用来源、不要编造等，有时能减少幻觉。

## 高质量prompt

角色 + 任务 + 背景 + 格式 + 边界”

# 性格，优点缺点

自我驱动

- 能主动学习新技术
- 遇到问题愿意深挖原理

缺点：

有时在多任务并行时，会在任务优先级判断上出现模糊，可能会影响整体工作节奏。

# 自我介绍

**面试官，您好！我叫王朔宇。目前就读于墨尔本大学数据科学专业，**

### **首先基本情况：**

**大学期间学习过计算机网络、数据库等基础课程**

**实习中完成接口开发，**

**上学期间也利用课外时间学习了 Spring 等框架，并做了一些开源项目 。**

**我做过一个基于 Spring Boot 的单体秒杀项目，主要是为了学习高并发场景的处理。这个项目里我用到了 Redis 做缓存，搭配数据库实现了库存预减、请求限流等功能。**

**另一个是spring cloud alibaba的微服务商城项目，使用docker部署，整体是从 0 到 1 自己动手搭建的，算是对微服务体系有了比较完整的实践认知。**

### **个人优势**

**自主学习能力：平常也会通过阅读源码、技术文档、书籍等来提升自己的专业水平**

**自主解决能力：遇到问题会通过自己查资料、分析等去解决，如果实在解决不了，会寻求老师或者导师的帮助**

**以上就是我的自我介绍**

### 英文版

Hello, Interviewer. my name is Shuoyu Wang. 

I’m currently studying at the University of Melbourne, majoring in Data Science.

and My undergraduate degree is from Beijing Forestry University, majoring in Data Science and Big Data Technology.

During my studies, I took computer science courses such as computer networks and databases. 

Outside the class, ==I spend my time to learning backend frameworks like Spring Boot and participated in some open-source projects.==

One of the projects I worked on was built with Spring Boot. ==The main purpose was to learn how to handle high-concurrency statution. In this project, I used Redis for caching.==

==I also built a microservice platform based on Spring Cloud Alibaba ecosystem. This project was deployed using Docker, which gave me a strong understanding of how to design and implement a microservices architecture.==

In terms of self-learning, I often improve my technical skills by reading source code, documentation, and some books.

That’s all my self-introduction. Thank you for your time.

# 既然mysql的功能pgsql都可以实现，为什么选择pgsql？

### 写：

MySQL 使用==写锁定==来实现真正的并发性

但是，PostgreSQL 内置了多版本并发控制（MVCC）支持，没有读写锁定。这样，如果要进行==频繁并发的写入操作==，则 PostgreSQL 数据库的表现会更好。

### 读：

PostgreSQL 会创建一个新的系统进程，为每个连接到数据库的用户分配大量内存（大约 10MB）。它需要内存密集型资源才能针对多个用户进行扩展。

另一方面，MySQL 为多个用户使用单一进程。因此，对于主要向用户读取和显示数据的应用程序，MySQL 数据库的表现优于 PostgreSQL。

### 其他

与主流地理空间工具（如QGIS等）相同的底层库

基于开源计算几何库：栅格/矢量数据格式处理，坐标系投影转换，2D/3D几何计算
