##  消息队列面试题

[![](https://cdn.xiaolincoding.com/mianshiya.png)](https://mianshiya.com/?shareCode=xeu1wi)

##  消息队列场景

###  *** 消息队列怎么选型？**

**RabbitMQ：**

- ==支持多种消息队列协议==；管理界面较丰富；==社区比较活跃==；==延迟低==。
- 性能上有瓶颈；使用 Erlang，不适合二次开发
- 文档全、控制台好用

**RocketMQ：**

- 单机==吞吐量==十万级；可用性非常高，分布式架构；消息可以做到==0丢失==；不会因为堆积导致性能下降；==源码是java==
- 社区活跃度一般

**Kafka**：

- 最大的优点就是==吞吐量高==；==消息有序==, 通过控制能够保证所有消息被消费且仅被消费一次
- “攒一波再处理”导致延迟比较高

Kafka、ActiveMQ、RabbitMQ、RocketMQ来进行不同维度对比。

|   **特性**   |     **Kafka**      |    **RabbitMQ**    |   **RocketMQ**   |
| :----------: | :----------------: | :----------------: | :--------------: |
|  **吞吐量**  |   极高（百万级）   |    中等（万级）    |   高（十万级）   |
|   **延迟**   |       毫秒级       | 微秒级（内存队列） |      毫秒级      |
|  **可靠性**  |    高（持久化）    |   高（镜像队列）   | 极高（事务消息） |
| **顺序消息** |     分区内有序     |       不保证       |  全局/分区有序   |
| **事务支持** | 有限（需外部实现） |       不支持       |     原生支持     |
| **协议支持** |     自定义协议     |  多协议（AMQP等）  |    自定义协议    |
| **适用场景** |    大数据流处理    |    企业应用集成    | 金融/电商高并发  |

| **业务场景**                           | **推荐消息中间件**  | **原因**                                 |
| -------------------------------------- | ------------------- | ---------------------------------------- |
| **传统企业应用，关注可靠性、灵活性**   | RabbitMQ            | 支持 AMQP 协议，易上手、功能全面         |
| **电商核心链路，顺序 + 事务 + 高可靠** | RocketMQ            | 支持分布式事务、顺序消息，延迟消息       |
| **日志采集、指标、流式大数据处理**     | Kafka               | ==高吞吐量，适合大数据场景，强堆积能力== |
| **低延迟金融交易系统**                 | RabbitMQ / RocketMQ | 低延迟，事务支持，可靠性高               |
| **海量数据推送、消息堆积不怕延迟**     | Kafka               | ==批量处理、磁盘存储，适合高并发日志==   |

选型的时候，我们需要根据业务场景，结合上述特性来进行选型。

比如你要支持天猫双十一类超大型的秒杀活动，这种一锤子买卖，那管理界面、消息回溯啥的不重要。

我们需要看什么？看吞吐量！

所以优先选Kafka和RocketMQ这种更高吞吐的。

比如做一个公司的中台，对外提供能力，那可能会有很多主题接入，这时候主题个数又是很重要的考量，像Kafka这样百级的，就不太符合要求，可以根据情况考虑千级的RocketMQ，甚至百万级的RabbitMQ。

又比如是一个金融类业务，那么重点考虑的就是稳定性、安全性，分布式部署的Kafka和Rocket就更有优势。

特别说一下时效性，RabbitMQ以微秒的时效作为招牌，但实际上毫秒和微秒，在绝大多数情况下，都没有感知的区别，加上网络带来的波动，这一点在生产过程中，反而不会作为重要的考量。

其它的特性，如消息确认、消息回溯，也经常作为考量的场景，管理界面的话试公司而定了，反正我呆过的地方，都不看重这个，毕竟都有自己的运维体系。

###  消息队列使用场景有哪些？

+   **解耦**：可以在多个系统之间进行解耦，将原本通过网络之间的调用的方式改为使用MQ进行消息的异步通讯，只要该操作不是需要同步的，就可以改为使用MQ进行不同系统之间的联系，这样项目之间不会存在耦合，系统之间不会产生太大的影响，就算一个系统挂了，也只是消息挤压在MQ里面没人进行消费而已，不会对其他的系统产生影响。
+   **异步**：加入一个操作设计到好几个步骤，这些步骤之间不需要同步完成，比如客户去创建了一个订单，还要去客户轨迹系统添加一条轨迹、去库存系统更新库存、去客户系统修改客户的状态等等。这样如果这个系统都直接进行调用，那么将会产生大量的时间，这样对于客户是无法接收的；并且像添加客户轨迹这种操作是不需要去同步操作的，如果使用MQ将客户创建订单时，将后面的轨迹、库存、状态等信息的更新全都放到MQ里面然后去异步操作，这样就可加快系统的访问速度，提供更好的客户体验。
+   **削峰**：一个系统访问流量有高峰时期，也有低峰时期，比如说，中午整点有一个抢购活动等等。比如系统平时流量并不高，一秒钟只有100多个并发请求，系统处理没有任何压力，一切风平浪静，到了某个抢购活动时间，系统并发访问了剧增，比如达到了每秒5000个并发请求，而我们的系统每秒只能处理2000个请求，那么由于流量太大，我们的系统、数据库可能就会崩溃。这时如果使用MQ进行流量削峰，将用户的大量消息直接放到MQ里面，然后我们的系统去按自己的最大消费能力去消费这些消息，就可以保证系统的稳定，只是可能要跟进业务逻辑，给用户返回特定页面或者稍后通过其他方式通知其结果

###  *** 消息重复消费怎么解决？**

生产端为了保证消息发送成功，可能会重复推送(直到收到成功ACK)，会产生重复消息。但是一个成熟的MQ Server框架一般会想办法解决，避免存储重复消息(比如：空间换时间，存储已处理过的message\_id)，给生产端提供一个幂等性的发送消息接口。

但是消费端却无法根本解决这个问题，在高并发标准要求下，拉取消息+业务处理+提交消费位移需要做事务处理，另外消费端服务可能宕机，很可能会拉取到重复消息。

所以，只能业务端自己做控制，==**对于已经消费成功的消息，本地数据库表或Redis缓存业务标识，每次处理前先进行校验，保证幂等。**==

###  *** 消息丢失怎么解决的？**

使用一个消息队列，其实就分为三大块：**生产者、中间件、消费者**，所以要保证消息就是保证三个环节都不能丢失数据。

![img](https://cdn.xiaolincoding.com//picgo/1719381898719-af6c00bf-8760-4639-bd21-e6d422ef7779.webp)

+   **消息生产阶段**：生产者会不会丢消息，取决于生产者对于异常情况的处理是否合理。从消息被生产出来，然后提交<u>给 MQ 的过程中，只要能正常收到 （ MQ 中间件） 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，如果返回异常则进行消息重发</u>，那么这个阶段是不会出现消息丢失的。
+   **消息存储阶段**：Kafka 在使用时是部署一个集群，生产者在发布消息时，<u>队列中间件通常会写「多个节点」</u>，也就是有多个副本，这样一来，<u>即便其中一个节点挂了，也能保证集群的数据不丢失。</u>
+   **消息消费阶段**：<u>消费者接收消息+消息处理之后，才回复 ack 的话，那么消息阶段的消息不会丢失</u>。不能收到消息就回 ack，否则可能消息处理中途挂掉了，消息就丢失了。

###  使用消息队列还应该注意哪些问题？

需要考虑消息可靠性和顺序性方面的问题。

### *  消息队列的可靠性(消息丢失)、顺序性怎么保证？

消息可靠性可以通过下面这些方式来保证

+   **消息持久化**：确保消息队列能够持久化消息是非常关键的。在系统崩溃、重启或者网络故障等情况下，未处理的消息不应丢失。例如，像 ==RabbitMQ 可以通过配置将消息持久化到磁盘，通过将队列和消息都设置为持久化的方式==（设置`durable = true`），这样在服务器重启后，消息依然可以被重新读取和处理。
+   **消息确认机制**：==消费者在成功处理消息后，应该向消息队列发送确认==（acknowledgment）。消息队列只有收到确认后，才会将消息从队列中移除。如果没有收到确认，消息队列可能会在一定时间后重新发送消息给其他消费者或者再次发送给同一个消费者。以 Kafka 为例，消费者通过`commitSync`或者`commitAsync`方法来提交偏移量（offset），从而确认消息的消费。
+   **消息重试策略**：当消费者处理消息失败时，需要有合理的重试策略。可以设置==重试次数和重试间隔时间==。例如，在第一次处理失败后，等待一段时间（如 5 秒）后进行第二次重试，如果重试多次（如 3 次）后仍然失败，可以将消息发送到死信队列，以便后续人工排查或者采取其他特殊处理。

消息顺序性保证的方式如下：

+   **有序消息处理场景识别**：首先需要明确业务场景中哪些消息是需要保证顺序的。例如，在金融交易系统中，对于同用户的转账操作顺序是不能打乱的。对于需要顺序处理的消息，要确保消息队列和消费者能够按照特定的顺序进行处理。
+   **消息队列对顺序性的支持**：部分消息队列本身提供了顺序性保证的功能。比如 ==Kafka 可以通过将消息划分到同一个分区（Partition）来保证消息在分区内是有序的，消费者按照分区顺序读取消息就可以保证消息顺序==。但这也可能会限制消息的并行处理程度，需要在顺序性和吞吐量之间进行权衡。
+   **消费者顺序处理策略**：消费者在处理顺序消息时，应该避免并发处理可能导致顺序打乱的情况。例如，可以通过==单线程或者使用线程池并对顺序消息进行串行化处理==等方式，确保消息按照正确的顺序被消费。

> RocketMQ 通过“生产时==将同一业务标识（如订单ID）的消息路由到同一个队列 + 消费时单线程消费该队列==”的方式，

###  * **如何保证幂等写？**

幂等性是指 **同一操作的多次执行对系统状态的影响与一次执行结果一致**。例如，支付接口若因网络重试被多次调用，最终应确保仅扣款一次。实现幂等写的核心方案：

+   ==唯一标识（幂等键）==：客户端为每个请求生成全局唯一ID（如 UUID、业务主键），服务端校验该ID是否已处理，适用场景接口调用、消息消费等。
+   ==数据库事务 + 乐观锁==：通过<u>版本号或状态字段控制并发更新</u>，确保多次更新等同于单次操作，适用场景数据库记录更新（如余额扣减、订单状态变更）。
+   ==数据库唯一约束==：利用数据库唯一索引防止重复数据写入，适用场景数据插入场景（如订单创建）。
+   ==分布式锁==：通过锁机制保证同一时刻仅有一个请求执行关键操作，适用场景高并发下的资源抢夺（如秒杀）。
+   ==消息去重==：消息队列生产者为每条消息生成唯一的消息 ID，消费者在处理消息前，先检查该消息 ID 是否已经处理过，如果已经处理过则丢弃该消息。

###  消息队列是参考哪种设计模式？

是参考了==观察者模式和发布订阅模式==，两种设计模式思路是一样的，举个生活例子：

+   观察者模式：某公司给自己员工发月饼发粽子，是由公司的行政部门发送的，这件事不适合交给第三方，原因是“公司”和“员工”是一个整体
+   发布-订阅模式：某公司要给其他人发各种快递，因为“公司”和“其他人”是独立的，其唯一的桥梁是“快递”，所以这件事适合交给第三方快递公司解决

上述过程中，如果公司自己去管理快递的配送，那公司就会变成一个快递公司，业务繁杂难以管理，影响公司自身的主营业务，因此使用何种模式需要考虑什么情况两者是需要耦合的

> 观察者模式

观察者模式实际上就是一个一对多的关系，在观察者模式中存在一个主题和多个观察者，主题也是被观察者，当我们主题发布消息时，会通知各个观察者，观察者将会收到最新消息，图解如下：每个观察者首先订阅主题，订阅成功后当主题发送消息时会循环整个观察者列表，逐一发送消息通知。 ![img](https://cdn.xiaolincoding.com//picgo/1723798409094-5099fa2a-c72c-4c67-bab7-09bbca9e0834.webp)

> 发布订阅模式

发布订阅模式和观察者模式的区别就是发布者和订阅者完全解耦，通过中间的发布订阅中心进行消息通知，发布者并不知道自己发布的消息会通知给谁，因此发布订阅模式有三个重要角色，发布者->发布订阅中心->订阅者。

图解如下：当发布者发布消息到发布订阅中心后，发布订阅中心会将消息通知给所有订阅该发布者的订阅者 ![img](https://cdn.xiaolincoding.com//picgo/1723798423949-97ae81c8-3536-40c6-bcc6-1509a3056a04.webp)

##  RocketMQ

###  消息队列为什么选择RocketMQ的？

项目用的是 RocketMQ 消息队列。选择RocketMQ的原因是：

+   **开发语言优势**。RocketMQ 使用 ==Java 语言开发==，比起使用 Erlang 开发的 RabbitMQ 来说，有着更容易上手的阅读体验和受众。在遇到 RocketMQ 较为底层的问题时，大部分熟悉 Java 的同学都可以深入阅读其源码，分析、排查问题。
+   **社区氛围活跃**。RocketMQ 是阿里巴巴开源且内部在大量使用的消息队列，说明 RocketMQ 是的确经得起残酷的生产环境考验的，并且能够针对线上环境复杂的需求场景提供相应的解决方案。
+   **特性丰富**。根据 RocketMQ 官方文档的列举，其高级特性达到了 `12 种`，例如顺序消息、事务消息、消息过滤、定时消息等。顺序消息、事务消息、消息过滤、定时消息。RocketMQ 丰富的特性，能够为我们在复杂的业务场景下尽可能多地提供思路及解决方案。

###  RocketMQ和Kafka的区别是什么？如何做技术选型？

Kafka的优缺点：

+   优点：首先，Kafka的最大优势就在于它的高吞吐量，在普通机器4CPU8G的配置下，一台机器可以抗住十几万的QPS，这一点还是相当优越的。Kafka支持集群部署，如果部分机器宕机不可用，则不影响Kafka的正常使用。
+   缺点：==Kafka有可能会造成数据丢失==，因为它在收到消息的时候，并不是直接写到物理磁盘的，而是先写入到磁盘缓冲区里面的。Kafka功能比较的单一 主要的就是支持收发消息，高级功能基本没有，就会造成适用场景受限。

RocketMQ是阿里巴巴开源的消息中间件，优缺点

+   优点：支持功能比较多，比如延迟队列、消息事务等等，吞吐量也高，单机吞吐量达到 10 万级，支持大规模集群部署，线性扩展方便，Java语言开发，满足了国内绝大部分公司技术栈
+   缺点：性能相比 kafka 是弱一点，因为 kafka 用到了 sendfile 的零拷贝技术，而 RocketMQ 主要是用 mmap+write 来实现零拷贝。

该怎么选择呢？

+   如果我们业务只是收发消息这种单一类型的需求，而且可以允许小部分数据丢失的可能性，但是又要求==极高的吞吐量和高性能==的话，就直接选Kafka就行了，就好比我们公司想要收集和传输用户行为日志以及其他相关日志的处理，就选用的Kafka中间件。
+   如果公司的需要通过 ==mq 来实现一些业务需求==，比如延迟队列、消息事务等，公司技术栈主要是Java语言的话，就直接一步到位选择RocketMQ，这样会省很多事情。

###  RocketMQ延时消息的底层原理

总体的原理示意图，如下所示：

![img](https://cdn.xiaolincoding.com//picgo/1720428795952-bba954e9-c9b6-45c5-aa05-8cc1d49c0e3c.png)

broker 在接收到延时消息的时候，会将延时消息存入到延时Topic的队列中，然后ScheduleMessageService中，每个 queue 对应的定时任务会不停地被执行，检查 queue 中哪些消息已到设定时间，然后转发到消息的原始Topic，这些消息就会被各自的 producer 消费了。

###  RocektMQ怎么处理分布式事务？

**RocketMQ是一种==最终一致性==的分布式事务**，就是说它保证的是消息最终一致性，而不是像2PC、3PC、TCC那样强一致分布式事务

假设 **A** 给 **B** 转 **100块钱**，同时它们不是同一个服务上，现在目标是就是 **A** 减100块钱，**B** 加100块钱。

实际情况可能有四种：

+   1）就是A账户减100 （成功），B账户加100 （成功）
    
+   2）就是A账户减100（失败），B账户加100 （失败）
    
+   3）就是A账户减100（成功），B账户加100 （失败）
    
+   4）就是A账户减100 （失败），B账户加100 （成功）
    

这里 **第1和第2** 种情况是能够保证事务的一致性的，但是 **第3和第4** 是无法保证事务的一致性的。

那我们来看下RocketMQ是如何来保证事务的一致性的。

![img](https://cdn.xiaolincoding.com//picgo/1714663418978-cb16a341-5eef-4f2a-ac2f-2331f5249c31.png)

分布式事务的流程如上图：

+   1、A服务先发送个Half Message（是指暂不能被Consumer消费的消息。Producer 已经把消息成功发送到了Broker 端，但此消息被标记为暂不能投递状态，处于该种状态下的消息称为半消息。需要 Producer对消息的二次确认后，Consumer才能去消费它）给Brock端，消息中携带 B服务 即将要+100元的信息。
    
+   2、当A服务知道Half Message发送成功后，那么开始第3步执行本地事务。
    
+   3、执行本地事务(会有三种情况1、执行成功。2、执行失败。3、网络等原因导致没有响应)
    
+   4.1)、如果本地事务成功，那么Product像Brock服务器发送Commit,这样B服务就可以消费该message。
    
+   4.2)、如果本地事务失败，那么Product像Brock服务器发送Rollback,那么就会直接删除上面这条半消息。
    
+   4.3)、如果因为网络等原因迟迟没有返回失败还是成功，那么会执行RocketMQ的回调接口，来进行事务的回查。
    

从上面流程可以得知 只有A服务本地事务执行成功 ，B服务才能消费该message。

**那么** **A账户减100 （成功），B账户加100 （失败），这时候B服务失败怎么办？**

如果B最终执行失败，几乎可以断定就是代码有问题所以才引起的异常，因为消费端RocketMQ有重试机制，如果不是代码问题一般重试几次就能成功。

如果是代码的原因引起多次重试失败后，也没有关系，将该异常记录下来，由人工处理，人工兜底处理后，就可以让事务达到最终的一致性。

###  RocketMQ消息顺序怎么保证？

消息的有序性是指消息的消费顺序能够严格保存与消息的发送顺序一致。例如，一个订单产生了3条消息，分别是订单创建、订单付款和订单完成。在消息消费时，同一条订单要严格按照这个顺序进行消费，否则业务会发生混乱。同时，不同订单之间的消息又是可以并发消费的，比如可以先执行第三个订单的付款，再执行第二个订单的创建。

RocketMQ采用了局部顺序一致性的机制，实现了单个队列中的消息严格有序。也就是说，如果想要保证顺序消费，必须==将一组消息发送到同一个**队列**中，然后再由消费者进行注意消费==。

RocketMQ推荐的顺序消费解决方案是：安装业务划分不同的队列，然后将需要顺序消费的消息发往同一队列中即可，不同业务之间的消息仍采用并发消费。这种方式在满足顺序消费的同时提高了消息的处理速度，在一定程度上避免了消息堆积问题

RocketMQ 顺序消息的原理是：

+   ==在 Producer（生产者） 把一批需要保证顺序的消息发送到同一个 MessageQueue==
+   ==Consumer（消费者） 则通过加锁的机制来保证消息消费的顺序性，Broker 端通过对 MessageQueue 进行加锁，保证同一个 MessageQueue 只能被同一个 Consumer 进行消费。==

###  RocketMQ怎么保证消息不被重复消费

在业务逻辑中实现**幂等性**，确保即使消息被重复消费，也不会影响业务状态。例如，对于支付或转账类操作，可以使用唯一订单号或事务ID作为幂等性的标识符，确保同样的操作只会被执行一次。

###  RocketMQ消息积压了，怎么办？

导致消息积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了。

要解决积压的问题，可以通过**==扩容消费端的实例数==来提升总体的消费能力**。

如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将==**系统降级**，通过关闭一些不重要的业务==，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。

### *** RocketMQ如何保证消息不丢失？**

**生产端**：

- **同步发送** ：Producer 发出消息后会 **等待 Broker 返回 SendResult**(默认模式异步发送)

**Broker**:

- 开启同步刷盘、主从复制(默认是异步刷盘)
  - 通过集群实现队列多副本，需配置策略

- 队列和消息持久化

**消费端保障:**

- 默认**手动 ACK**，通过返回消费状态控制是否确认成功

- **重试机制** (RocketMQ 默认支持 **最多重试 16 次**，可配置）
- 消费多次失败后，自动发送到该消费者组的**死信队列**, 后台可监听 DLQ 做报警、补偿、人工处理等

##  kafka

### 结构体

```
Producer --> Topic --> Partition --> Segment(log file) --> Message
```

#### Topic

- 类似于消息的分类或通道。
- 一个 Topic 可以有多个 Partition。
- Topic 本身不存储消息，消息实际存在 Partition 中

#### Partition

- topic 的物理分区，是消息存储的最小单位。
- 每个 Partition 是一个==有序、可追加写入==的消息队列（日志文件）。
- 具有如下特性：
  - 顺序性：分区内消息是有序的。
  - Offset：每条消息在 Partition 中都有唯一的偏移量。
  - 可以在多个 broker 之间分布以实现并行消费。

#### Segment

- Partition 在物理存储上由多个 segment 文件组成。
- 每个 segment 有固定大小（默认1GB），超过后滚动生成新 segment。

#### Offset

- 每条消息都有一个递增的 offset。
- Kafka 并不会主动维护消费者的消费位置，offset 需要客户端自行维护

###  对Kafka有什么了解吗？

Kafka特点如下：

+   高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。
+   可扩展性：kafka集群支持热扩展
+   持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
+   容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
+   高并发：支持数千个客户端同时读写

###  Kafka 为什么这么快？

+   **顺序写入优化**：Kafka将消息==顺序写入磁盘==，减少了磁盘的寻道时间。这种方式比随机写入更高效，因为磁盘读写头在顺序写入时只需移动一次。
+   **批量处理技术**：Kafka支持==批量发送消息==，这意味着生产者在发送消息时可以等待直到有足够的数据积累到一定量，然后再发送。这种方法减少了网络开销和磁盘I/O操作的次数，从而提高了吞吐量。
+   **零拷贝技术**：Kafka使用零拷贝技术，可以==直接将数据从磁盘发送到网络套接字==，避免了在用户空间和内核空间之间的多次数据拷贝。这大幅降低了CPU和内存的负载，提高了数据传输效率。
+   **压缩技术**：Kafka支持==对消息进行压缩==，这不仅减少了网络传输的数据量，还提高了整体的吞吐量。

###  kafka的模型介绍一下，kafka是推送还是拉取？

> 消费者模型

消息由生产者发送到kafka集群后，会被消费者消费。一般来说我们的消费模型有两种：推送模型(psuh)和拉取模型(pull)。

**推送模型（push）**

+   基于推送模型（push）的消息系统，有消息代理记录消费者的消费状态。
+   消息代理在将消息推送到消费者后，标记这条消息已经消费，但这种方式无法很好地保证消费被处理。
+   如果要保证消息被处理，消息代理发送完消息后，要设置状态为“已发送”，只要收到消费者的确认请求后才更新为“已消费”，这就需要代理中记录所有的消费状态，但显然这种方式不可取。

缺点：

+   **push模式很难适应消费速率不同的消费者**
+   因为消息发送速率是由broker决定的，push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。

**拉取模型(pull)**

kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序拉取每个分区的消息。

![img](https://cdn.xiaolincoding.com//picgo/1717921512808-fb0372de-7ada-4bc4-bfb5-7e599d9335ac.png)

说明：

+   有两个消费者（不同消费者组）拉取同一个主题的消息，消费者A的消费进度是3，消费者B的消费进度是6。
+   消费者拉取的最大上限通过最高水位（watermark）控制，生产者最新写入的消息如果还没有达到备份数量，对消费者是不可见的。
+   这种由消费者控制偏移量的优点是：**消费者可以按照任意的顺序消费消息**。比如，消费者可以重置到旧的偏移量，重新处理之前已经消费过的消息；或者直接跳到最近的位置，从当前的时刻开始消费。

> 消费者组

kafka 消费者是以consumer group消费者组的方式工作，由一个或者多个消费者组成一个组，共同消费一个topic。每个分区在同一时间只能由group中的一个消费者读取，但是多个group可以同时消费这个partition。

![img](https://cdn.xiaolincoding.com//picgo/1717921705776-04ba7b13-4350-4444-b332-9b3607096fe2.png)

上图中，有一个由三个消费者组成的group，有一个消费者读取主题中的两个分区，另外两个分别读取一个分区。某个消费者读取某个分区，也可以叫做某个消费者是某个分区的拥有者。

优点在于：

+   消费者可以通过水平扩展的方式同时读取大量的消息。
+   如果一个消费者失败了，那么其他的group成员会自动负载均衡读取之前失败的消费者读取的分区。

> 消费方式

kafka 消费者采用 pull（拉）模式从 broker中读取数据。

pull 的优点：

+   pull 模式可以根据 consumer 的消费能力以适当的速率消费消息

缺点：

+   如果 kafka 没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有数据可供消费，consumer 会等待一段时间之后再返回，这段时长即为 timeout。

### *** Kafka确保消息不遗漏**

#### 生产者：

- 确认机制(ACKs)
  - `acks=0`：生产者不等待任何确认，可能丢失消息
  - `acks=1`：等待leader确认(默认)，可能丢失如果leader宕机且未复制
  - `acks=all`/-1：等待所有ISR(同步副本)确认，最安全但延迟最高
- 重试机制`retries`
- 幂等生产者`enable.idempotence=true`

#### Broker

- 副本机制(Replication)
- 持久化
- Leader选举

#### 消费者端保证

- 手动提交偏移量
- 正确处理消费逻辑
- 消费者组重平衡

> 在极端情况下(如所有副本同时宕机)，仍有可能丢失数据，因此关键业务场景建议结合业务日志或数据库进行补充校验。

### * **Kafka中消息的重复消费问题如何解决？**

**候选人**：

通过以下方法解决Kafka中的重复消费问题：

- 禁用自动提交offset，==手动控制offset提交时机==。
- 确保消息消费的幂等性，例如通过==唯一主键或分布式锁==。

###  *** Kafka 如何保证顺序读取消息？**

==Kafka 可以保证在同一个分区内消息是有序的==，生产者写入到同一分区的消息会按照写入顺序追加到分区日志文件中，消费者从分区中读取消息时也会按照这个顺序。这是 Kafka 天然具备的特性。

要在 Kafka 中保证顺序读取消息，需要结合生产者、消费者的配置以及合适的业务处理逻辑来实现。以下具体说明如何实现顺序读取消息：

+   生产者端确保消息顺序：为了保证消息写入同一分区从而确保顺序性，生产者需要将消息发送到指定分区。可以通过自定义分区器来实现，通过为消息指定相同的Key，保证相同Key的消息发送到同一分区。
+   消费者端保证顺序消费：消费者在消费消息时，需要单线程消费同一分区的消息，这样才能保证按顺序处理消息。如果使用多线程消费同一分区，就无法保证消息处理的顺序性。



Kafka 本身不能保证跨分区的消息顺序性，如果需要全局的消息顺序性，通常有以下两种方法：

+   ==只使用一个分区==：将所有消息都写入到同一个分区，消费者也只从这个分区消费消息。但这种方式会导致 Kafka 的并行处理能力下降，因为 Kafka 的性能优势在于多分区并行处理。
+   业务层面保证：在业务代码中==对消息进行编号或添加时间戳等标识==，消费者在消费消息后，根据这些标识对消息进行排序处理。但这种方式会增加业务代码的复杂度。

###  *** Kafka 消息积压怎么办？**

Kafka 消息积压是一个常见的问题，它可能会导致数据处理延迟，甚至影响业务的正常运行，下面是一些解决 Kafka 消息积压问题的常用方法：

+   ==增加消费者实例==可以提高消息的消费速度，从而缓解积压问题。你需要确保消费者组中的消费者数量不超过分区数量，因为一个分区同一时间只能被一个消费者消费。
+   ==增加 Kafka 主题的分区数量==可以提高消息的并行处理能力。在创建新分区后，你需要重新平衡消费者组，让更多的消费者可以同时消费消息。

> 临时扩容
>
> - 将分区数从 6 增加到 12（需提前规划 Key 设计）。
> - 启动 12 个消费者实例，每个处理 1 个分区。
>
> 流量回落后缩容：
>
> - 停止 6 个消费者，剩余 6 个消费者各处理 2 个分区。
> - 分区数保持 12（不再减少，避免影响历史数据）。

###  Kafka为什么一个分区只能由消费者组的一个消费者消费？这样设计的意义是什么？

同一时刻，一条消息只能被组中的一个消费者实例消费

![img](https://cdn.xiaolincoding.com//picgo/1724653429445-22f12b17-9413-4611-9d78-c3599d8c7906.png)

如果两个消费者负责同一个分区，那么就意味着两个消费者同时读取分区的消息，由于消费者自己可以控制读取消息的offset，就有可能C1才读到2，而C1读到1，C1还没处理完，C2已经读到3了，则会造成很多浪费，因为这就相当于多线程读取同一个消息，==会造成消息处理的重复，且不能保证消息的顺序。==

###  如果有一个消费主题topic，有一个消费组group，topic有10个分区，消费线程数和分区数的关系是怎么样的？

topic下的==一个分区只能被同一个consumer group下的一个consumer线程来消费==，但反之并不成立，即一个consumer线程可以消费多个分区的数据，比如Kafka提供的ConsoleConsumer，默认就只是一个线程来消费所有分区的数据。

![img](https://cdn.xiaolincoding.com//picgo/1732606891790-bf7cb080-0209-46bc-80b4-5f96ad88453f.webp)

所以，**分区数决定了同组消费者个数的上限**。

如果你的分区数是N，那么最好线程数也保持为N，这样通常能够达到最大的吞吐量。超过N的配置只是浪费系统资源，因为多出的线程不会被分配到任何分区。

###  *** Kafka 和 RocketMQ 消息确认机制有什么不同？**

Kafka的消息确认ACK机制有三种：0，1，-1：

+   **ACK=0**：这是最不可靠的模式。生产者在发送消息后==不会等待来自服务器的确认==。这意味着消息可能会在发送之后丢失，而生产者将无法知道它是否成功到达服务器。
+   **ACK=1**：这是默认模式，也是一种折衷方式。在这种模式下，生产者会在消息发送后==等待来自分区<u>领导者</u>（leader）的确认，但不会等待所有副本（replicas）的确认==。这意味着只要消息被写入分区领导者，生产者就会收到确认。如果分区领导者成功写入消息，但在同步到所有副本之前宕机，消息可能会丢失。
+   **ACK=-1**：这是最可靠的模式。在这种模式下，生产者会在消息发送后==等待所有副本的确认==。只有在所有副本都成功写入消息后，生产者才会收到确认。这确保了消息的可靠性，但会导致更长的延迟。

> 消费者 Offset 机制：
>
> Offset 是消费者在分区（Partition）中的消费位置标识，避免重复消费或丢失消息。
>
> 

RocketMQ 提供了三种消息发送方式：同步发送、异步发送和单向发送：

+   **同步发送**：是指消息发送方发出一条消息后，会在收到服务端同步响应之后才发下一条消息的通讯方式。应用场景非常广泛，例如重要通知邮件、报名短信通知、营销短信系统等。
+   **异步发送**：是指发送方发出一条消息后，不等服务端返回响应，接着发送下一条消息的通讯方式，但是需要实现异步发送回调接口（SendCallback）。消息发送方在发送了一条消息后，不需要等待服务端响应即可发送第二条消息。发送方通过回调接口接收服务端响应，并处理响应结果。适用于链路耗时较长，对响应时间较为敏感的业务场景，例如，视频上传后通知启动转码服务，转码完成后通知推送转码结果等。
+   **单向发送**：发送方只负责发送消息，不等待服务端返回响应且没有回调函数触发，即只发送请求不等待应答。此方式发送消息的过程耗时非常短，一般在微秒级别。适用于某些耗时非常短，但对可靠性要求并不高的场景，例如日志收集。

### Kafka的高可用机制了解吗？

Kafka的高可用性主要通过以下机制实现：

- 集群部署，多broker实例，单点故障不影响整体服务。
- 复制机制，每个分区有多个副本，leader和follower，leader故障时从follower中选举新leader。

###  Kafka 和 RocketMQ 的 broker 架构有什么区别

+   Kafka 的 broker 架构：Kafka 的 broker 架构采用了分布式的设计，==每个 Kafka broker 是一个独立的服务实例==，负责存储和处理一部分消息数据。
    +   每个 topic 分成多个分区，分布在多个 broker 上

+   RocketMQ 的 broker 架构：RocketMQ 的 broker 架构也是分布式的，但是每个 ==RocketMQ broker 有主从之分，一个主节点和多个从节点组成一个 broker 集群==。主节点负责消息的写入和消费者的拉取，从节点负责消息的复制和消费者的负载均衡，提高了消息的可靠性和可用性。

### **Kafka重平衡机制，怎么避免，ISR选主机制**

重平衡机制是消费者组内的分区重新分配过程，当消费者加入或离开时触发，这可能会导致服务暂停，影响系统性能

常见的触发原因包括消费者实例的增减、心跳超时、处理时间过长等

- 增大session超时时间和心跳检测间隔 session.timeout.ms + heartbeat.interval.ms 
- 使用固定分区（assign）而不是订阅（subscribe）

ISR（In-Sync Replicas）机制：

- ISR（In-Sync Replicas）指与leader保持同步的follower副本。

- 当leader故障时，优先从ISR中选举新leader，因为它们数据一致性更高。

  - Leader 故障检测：Controller 监控 Broker 心跳，发现 Leader 下线。

  - ISR 选主：优先从 ISR 中选择新 Leader（保证数据一致性）。

  - 非 ISR 选主（兜底）：若 ISR 为空且 unclean.leader.election.enable=true，允许从非 ISR 副本选主（可能丢失数据）。

### 时间轮

1. 时间轮的基本概念

时间轮采用一个环形的数据结构（类似于环形缓冲区），将时间划分为若干个固定的时间间隔（槽）。每个槽用来存放在该时间间隔内需要执行的任务。

一个指针会周期性地沿着时间轮移动，当指针指向某个槽时，该槽内的所有任务如果到达了预定的执行时间，就会被触发执行。

2. 时间轮的工作原理

• 任务插入

当有一个需要延迟执行的任务时，会根据它的延时时间计算出应该插入到哪一个槽中。这个计算类似于取模运算，将延迟时间映射到时间轮上的某个具体槽位。

• 时间流逝与任务触发

随着时间的推进，指针逐步移动到下一个槽。当指针到达某个槽时，系统会检查槽内的任务，如果任务的预定执行时间已经到达，就执行该任务。

##  RabbitMQ

###  RabbitMQ的特性你知道哪些？

RabbitMQ 以 **可靠性**、**灵活性** 和 **易扩展性** 为核心优势，适合需要稳定消息传递的复杂系统。其丰富的插件和协议支持使其在微服务、IoT、金融等领域广泛应用，比较核心的特性有如下：

+   **持久化机制**：RabbitMQ 支持消息、队列和交换器的持久化。当启用持久化时，消息会被写入磁盘，即使 RabbitMQ 服务器重启，消息也不会丢失。例如，在声明队列时可以设置 `durable` 参数为 `true` 来实现队列的持久化：

```python
import pika

connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
channel = connection.channel()

 声明一个持久化队列
channel.queue_declare(queue='durable_queue', durable=True)
```

+   **消息确认机制**：提供了生产者确认和消费者确认机制。生产者可以设置 `confirm` 模式，当消息成功到达 RabbitMQ 服务器时，会收到确认消息；消费者在处理完消息后，可以向 RabbitMQ 发送确认信号，告知服务器该消息已被成功处理，服务器才会将消息从队列中删除。
+   **镜像队列**：支持创建镜像队列，将队列的内容复制到多个节点上，提高消息的可用性和可靠性。当一个节点出现故障时，其他节点仍然可以提供服务，确保消息不会丢失。
+   **多种交换器类型**：RabbitMQ 提供了多种类型的交换器，如直连交换器（Direct Exchange）、扇形交换器（Fanout Exchange）、主题交换器（Topic Exchange）和头部交换器（Headers Exchange）。不同类型的交换器根据不同的规则将消息路由到队列中。例如，扇形交换器会将接收到的消息广播到所有绑定的队列中；主题交换器则根据消息的路由键和绑定键的匹配规则进行路由。

###  RabbitMQ的底层架构是什么？

![img](https://cdn.xiaolincoding.com//picgo/1725873091567-7b267c53-2069-46a4-85bc-63f4b712071f.png)

以下是 RabbitMQ 的一些核心架构组件和特性：

+   **核心组件**：生产者负责发送消息到 RabbitMQ、消费者负责从 RabbitMQ 接收并处理消息、RabbitMQ 本身负责存储和转发消息。
+   **交换机**：交换机接收来自生产者的消息，并根据 routing key 和绑定规则将消息路由到一个或多个队列。
+   **持久化**：RabbitMQ 支持消息的持久化，可以将消息保存在磁盘上，以确保在 RabbitMQ 重启后消息不丢失，队列也可以设置为持久化，以保证其结构在重启后不会丢失。
+   **确认机制**：为了确保消息可靠送达，RabbitMQ 使用确认机制，消费者在处理完消息后发送确认给 RabbitMQ，未确认的消息会重新入队。
+   **高可用性**：RabbitMQ 提供了集群模式，可以将多个 RabbitMQ 实例组成一个集群，以提高可用性和负载均衡。通过镜像队列，可以在多个节点上复制同一队列的内容，以防止单点故障。

### **RabbitMQ如何保证消息不丢失？**

**候选人**：

我们使用RabbitMQ来确保MySQL和Redis间数据双写的一致性，这要求我们实现消息的高可用性，具体措施包括：

1. 开启==生产者确认机制==，确保消息能被送达队列，如有错误则记录日志并修复数据。
2. 启用==持久化功能==，保证消息在未消费前不会在队列中丢失，需要对交换机、队列和消息本身都进行持久化。
3. 对消费者开启==手动确认机制==

### **RabbitMQ消息的重复消费问题如何解决？**

通过==业务唯一标识==检查数据库中数据是否存在，若不存在则处理消息，若存在则忽略，避免重复消费。

> 下单消息 ；支付成功消息 ；用户注册消息 

### **RabbitMQ中死信交换机了解吗？**（RabbitMQ延迟队列有了解过吗？）

主要通过死信交换机和TTL（消息存活时间）来实现。
- 消息若超时未消费则变为死信，队列可绑定死信交换机，实现延迟功能。
- 另一种方法是==安装RabbitMQ的死信插件，简化配置，在声明交换机时指定为死信交换机，并设置消息超时时间。==

### 如果有100万消息堆积在MQ，如何解决？

1. ==提高消费者消费能力==，如使用多线程。
2. ==增加消费者数量==，采用工作队列模式，让多个消费者并行消费同一队列。
3. ==扩大队列容量，使用RabbitMQ的惰性队列==，支持数百万条消息存储，直接存盘而非内存。

### RabbitMQ的高可用机制了解吗？（镜像队列）

使用RabbitMQ集群，采用镜像队列模式，一主多从结构。

- 主节点处理所有操作并同步给从节点，若主节点宕机，从节点可接替为主节点，但需注意数据同步的完整性。

## 深入理解kafka

### 概念

**主题：**Kafka中的消息以主题为单位进行归类，生产者负责将消息发送到特定的主题（发送到Kafka集群中的每一条消息都要指定一个主题），而消费者负责订阅主题并进行消费。

**分区：**主题是一个逻辑上的概念，它还可以细分为多个分区，一个分区只属于单个主题

offset是消息在分区中的唯一标识， Kafka通过它来保证消息在分区内的顺序性，不过 offset并不跨越分区，也就是说，Kafka保证的是==分区有序而不是主题有序==。

> Kafka中的分区可以分布在不同的服务器（broker）上
>
> 一个主题可以横跨多个broker，以此来提供比单个 broker更强大的性能。
>
> Kafka 为分区引入了多副本（Replica）机制， 通过增加副本数量可以提升容灾能力。
>
> 同一分区的不同副本中保存的是相同的消息（在同一时刻，副本之间并非完全一样），副本之间是“一主多从”的关系， 其中leader副本负责处理读写请求，follower副本只负责与leader副本的消息同步。

![image-20250405090641045](./11.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20250405090641045.png)

如图所示，Kafka集群中有4个broker，<u>某个主题中有3个分区</u>，且副本因子（即副本个数）也为 3，如此<u>每个分区便有1个leader副本和2个follower副本</u>。生产者和消费者只与leader副本进行交互

==Consumer 使用拉（PuIl）模式==从服务端拉取消息， 并且保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消费，这样就不会造成消息丢失。

分区中的<u>所有副本统称为**AR**</u>（Assigned Replicas）。所有<u>与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-SyncReplicas）</u>，ISR集合是AR集合中的一个子集。消息会先发送到leader副本，然后follower副本才能从 leader副本中拉取消息进行同步，同步期间内 follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度的同步”是指可忍受的滞后范围，这个范围可以通过参数进行配置。<u>与leader 副本同步滞后过多的副本（不包括leader副本）组成 OSR ( Out-of-Sync Replicas)</u> , 由此可见， ==AR=ISR+OSR。==在正常情况下，所有的 follower 副本都应该与 leader 副本保持一定程度的同步，即 AR=ISR，OSR集合为空。

leader副本负责维护和跟踪ISR集合中所有 follower副本的滞后状态，<u>当follower副本落后太多或失效时，leader副本会把它从ISR集合中剔除。如果**OSR**集合中有follower副本“追上”了leader副本， 那么leader副本会把它从OSR集合转移至**ISR**集合</u>。 默认情况下，当leader副本发生故障时，只有在ISR 集合中的副本才有资格被选举为新的leader，而在 OSR集合中的副本则没有任何机会（不过这个原则也可以通过修改相应的参数配置来改变）。

ISR与HW和LEO也有紧密的关系。HW是High Watermark的缩写，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个 offset之前的消息。

![image-20250405091331011](./11.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%9D%A2%E8%AF%95%E9%A2%98.assets/image-20250405091331011.png)

这个日志文件中有9条消息，第一条消息的 offset （LogStartOffset）为O，最后一条消息的offset为8, offset为9的消息用虚线框表示，代表下一条待写入的消息。日志文件的HW为6，表示消费者<u>只能拉取到offset在0至5之间的消息</u>，而offset为6的消息对消费者而言是不可见的。

LEO是Log End Offset的缩写，它标识当前日志文件中下一条待写入消息的offset，图中offset为 9的位置即为当前日志文件的LEO，<u>LEO的大小相当于当前日志分区中最后一条消息的offset值加1</u>。分区 SR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW，对消费者而言只能消费HW之前的消息。

> 同一个key的消息会被划分到同一个分区中

### 生产者

发送消息主要有三种模式：发后即忘 （fre-and-forget）、同步（sync）及异步 (async) .

消息在通过`send（）`方法发往broker的过程中， 有可能需要经过==拦截器 （Interceptor）、序列化器 （Serializer）和分区器 （Partitioner）==的一系列作用之后才能被真正地发往 broker。

- 拦截器一般不是必需的，而序列化器是必需的。
- 如果消息ProducerRecord中没有指定partition 字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区

> 那么默认的分区器会对 key 进行哈希（采用MurmurHash2 算法，具备高运算性能及低碰撞率），最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区。如果key为null，那么消息将会以轮询的方式发往主题内的各个可用分区。